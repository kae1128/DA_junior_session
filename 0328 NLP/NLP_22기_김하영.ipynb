{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 서브워드 토크나이저(Subword Tokenizer)\n",
        "하나의 단어를 더 작은 단위의 의미있는 서브워드로 분리하는 전처리 작업을 의미한다. 예를 들어 birthplace는 birth와 place로 분리할 수 있다. 서브워드 토크나이저가 활용되는 이유는 기계가 모르는 단어를 인식하지 못하는 OOV 문제를 해결하기 위함이다. OVV(Out-Of-Vocabulary)는 기계가 아무리 학습흘 많이 하더라도 모르는 단어가 있을 수밖에 없기 때문에 발생하는 문제다. 따라서, 기계가 인식하지 못하는 단어를 더 작은 단위로 분리하는 서브워드 토크나이저를 통해 해당 문제를 완화할 수 있다."
      ],
      "metadata": {
        "id": "K9P1lXR7Z68z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Byte Pair Encoding(BPE)\n",
        "글자(Character) 단위에서 점차적으로 단어 집합(vocabulary)을 만들어 내는 Bottom up 방식을 사용한다. (단어집합이란, 중복을 배제한 단어들의 집합을 의미한다.)\n",
        "\n",
        "기존 방식에서 low, lower, newest, widest라는 단어 집합이 있다면, lowest라는 단어가 등장했을 때 제대로 인식하지 못한다.\n",
        "\n",
        "반면 BPE 방식을 활용한다면, \n",
        "+ 글자 단위 분리: l o w 와 같이 단어를 글자 단위로 분리한다\n",
        "+ 단어 집합 생성: 분리한 글자로 다시 각 유니그램이 중복되지 않는 단어 집합으로 만든다. \n",
        "+ 유니그램 쌍 통합: 빈도가 가장 높은 유니그램 쌍을 통합한다. 예를 들어, (e,s)는 es로 통합할 수 있다. 이때, 빈도가 높은 유니그램 쌍을 하나로 통합하는 과정을 사용자가 임의로 지정한 횟수만큼 반복할 수 있다.\n",
        "\n",
        "결과적으로 위에서 생성된 단어집합을 참고하여 lowest 라는 단어를 low와 est 두 단어로 인코딩하게 된다."
      ],
      "metadata": {
        "id": "Vh6b7PlnqSG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, collections\n",
        "from IPython.display import display, Markdown, Latex"
      ],
      "metadata": {
        "id": "CCWRcY3nqO5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BPE 수행 횟수\n",
        "num_merges = 10"
      ],
      "metadata": {
        "id": "GiBYcdkMqfJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BPE에 활용할 단어\n",
        "dictionary = {'l o w </w>' : 5,\n",
        "         'l o w e r </w>' : 2,\n",
        "         'n e w e s t </w>':6,\n",
        "         'w i d e s t </w>':3\n",
        "         }"
      ],
      "metadata": {
        "id": "IqPkZjhJrsUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(dictionary):\n",
        "    # 유니그램의 pair들의 빈도수를 카운트\n",
        "    pairs = collections.defaultdict(int)\n",
        "    for word, freq in dictionary.items():\n",
        "        symbols = word.split()\n",
        "        for i in range(len(symbols)-1):\n",
        "            pairs[symbols[i],symbols[i+1]] += freq\n",
        "    print('현재 pair들의 빈도수 :', dict(pairs))\n",
        "    return pairs\n",
        "\n",
        "def merge_dictionary(pair, v_in):\n",
        "    v_out = {}\n",
        "    bigram = re.escape(' '.join(pair))\n",
        "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
        "    for word in v_in:\n",
        "        w_out = p.sub(''.join(pair), word)\n",
        "        v_out[w_out] = v_in[word]\n",
        "    return v_out\n",
        "\n",
        "bpe_codes = {}\n",
        "bpe_codes_reverse = {}\n",
        "\n",
        "for i in range(num_merges):\n",
        "    display(Markdown(\"### Iteration {}\".format(i + 1)))\n",
        "    pairs = get_stats(dictionary)\n",
        "    best = max(pairs, key=pairs.get)\n",
        "    dictionary = merge_dictionary(best, dictionary)\n",
        "\n",
        "    bpe_codes[best] = i\n",
        "    bpe_codes_reverse[best[0] + best[1]] = best\n",
        "\n",
        "    print(\"new merge: {}\".format(best))\n",
        "    print(\"dictionary: {}\".format(dictionary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "id": "MYfQkqTArzVQ",
        "outputId": "9467d0f0-8827-4ebb-b68d-b3d428c6f3af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 1"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 8, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('e', 's'): 9, ('s', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'e'): 3}\n",
            "new merge: ('e', 's')\n",
            "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w es t </w>': 6, 'w i d es t </w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 2"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'es'): 6, ('es', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'es'): 3}\n",
            "new merge: ('es', 't')\n",
            "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est </w>': 6, 'w i d est </w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 3"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est'): 6, ('est', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est'): 3}\n",
            "new merge: ('est', '</w>')\n",
            "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 4"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "new merge: ('l', 'o')\n",
            "dictionary: {'lo w </w>': 5, 'lo w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 5"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('lo', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "new merge: ('lo', 'w')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 6"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "new merge: ('n', 'e')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'ne w est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 7"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('ne', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "new merge: ('ne', 'w')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'new est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 8"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('new', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "new merge: ('new', 'est</w>')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 9"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "new merge: ('low', '</w>')\n",
            "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 10"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "new merge: ('w', 'i')\n",
            "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'wi d est</w>': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SentencePiece\n",
        "구글에서 공개한 SnetencePeice는 BPE 알고리즘과 Unigram Language Model Tokenizer를 구현할 수 있다. BPE와 달리 사전 토큰화 작업 없이 단어 분리 토큰화를 수행하므로 언어에 종속되지 않는다는 특징이 있다."
      ],
      "metadata": {
        "id": "EjCHSod7qd1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# text-classification"
      ],
      "metadata": {
        "id": "uWg4x8jbcy6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBlc99MTqekA",
        "outputId": "441b0d26-873f-436f-ce7e-2044e8540802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# GPU 사용 여부 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# 텍스트 인코딩\n",
        "text = \"Daewoo Hall is too far from the main gate\"\n",
        "encoded_text = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# 모델 적용\n",
        "output = model(**encoded_text.to(device))\n",
        "result = torch.argmax(output.logits, dim=1).cpu().detach().numpy()[0]\n",
        "\n",
        "# 결과 출력\n",
        "if result == 0:\n",
        "    print(\"Negative\")\n",
        "else:\n",
        "    print(\"Positive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7akvGEkFm65E",
        "outputId": "260c7c1e-ecf7-4d56-a82f-a74cd16b701c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bmuS0zt9pEjE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}